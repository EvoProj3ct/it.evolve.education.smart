## 1. Titolo del modulo
**IA, persone e responsabilità**

---

## 2. Descrizione sintetica
Questo modulo affronta il rapporto tra Intelligenza Artificiale e responsabilità umana, chiarendo perché le decisioni, il controllo e le conseguenze dell’uso dell’IA restano sempre in capo alle persone. È rivolto a professionisti, imprenditori e PMI non tecniche che utilizzano strumenti digitali e vogliono comprendere rischi, limiti e implicazioni dell’affidarsi a sistemi automatici nel lavoro quotidiano.

---

## 3. Contesto del modulo
Con la diffusione dell’Intelligenza Artificiale nei processi di lavoro, cresce la tendenza a delegare attività, valutazioni e decisioni agli strumenti automatici. Questo modulo nasce dall’esigenza di riportare l’attenzione sul ruolo centrale dell’essere umano: l’IA non è un soggetto responsabile, ma uno strumento. Comprendere chi decide, chi controlla e chi risponde degli errori è fondamentale per un utilizzo consapevole e professionale.

---

## 4. Obiettivi didattici
Al termine del modulo, il partecipante sarà in grado di:

- Comprendere perché la responsabilità dell’uso dell’IA è sempre umana  
- Riconoscere i principali rischi legati alla delega eccessiva agli strumenti automatici  
- Identificare situazioni in cui è necessario mantenere controllo e verifica  
- Sviluppare un atteggiamento critico nell’uso dell’IA nel lavoro

---

## 5. Contenuto del modulo

### 5.1 Testo principale
L’Intelligenza Artificiale viene spesso percepita come un’entità autonoma che prende decisioni al posto delle persone. In realtà, ogni sistema di IA agisce sempre all’interno di limiti stabiliti da chi lo progetta e da chi lo utilizza.

L’IA non è responsabile delle sue azioni: non ha consapevolezza, non comprende le conseguenze e non può rispondere degli errori. La responsabilità rimane sempre della persona che decide di usare lo strumento, che accetta o applica il risultato prodotto.

Uno dei rischi principali è la delega eccessiva. Quando un sistema produce risposte rapide e apparentemente corrette, è facile smettere di verificarle. Questo può portare a errori, informazioni scorrette o decisioni inappropriate, soprattutto in contesti complessi o delicati.

Un altro aspetto critico riguarda le distorsioni e i pregiudizi. L’IA lavora sui dati disponibili: se i dati sono incompleti o sbilanciati, anche i risultati lo saranno. Senza un controllo umano consapevole, questi problemi possono passare inosservati.

Usare l’IA in modo responsabile significa quindi mantenere sempre un ruolo attivo: fare domande, verificare le risposte, contestualizzare i risultati e decidere quando lo strumento è utile e quando non lo è.

---

### 5.2 Concetti chiave
- Responsabilità umana nell’uso dell’IA  
- Delega eccessiva e perdita di controllo  
- Necessità di verifica e supervisione  
- Distorsioni e limiti legati ai dati  
- Pensiero critico come competenza centrale

---

## 6. Esempi e applicazioni pratiche
- Caso realistico: utilizzo di un suggerimento automatico che viene applicato senza verifica e genera un problema operativo  
- Esempio dimostrativo: due risultati diversi prodotti a partire da informazioni di partenza simili, ma incomplete  
- Applicazione quotidiana: uso dell’IA come supporto decisionale, non come decisore finale

Gli esempi vanno raccontati come situazioni comuni nel lavoro, senza riferimenti a settori specifici.

---

## 7. Domande e interazione

### 7.1 Domande per il pubblico
- In quali attività tendi a fidarti di più degli strumenti automatici?  
- Quando è giusto delegare e quando no?  
- Quali controlli fai prima di usare un risultato prodotto da un sistema automatico?

---

### 7.2 Discussioni o esercizi
Esercizio di riflessione guidata:
Il relatore propone una situazione lavorativa comune e chiede ai partecipanti di indicare quali parti possono essere supportate dall’IA e quali richiedono necessariamente una decisione umana.

---

## 8. Azioni per il relatore
- Evidenziare che l’IA non prende decisioni, ma propone risultati  
- Riportare sempre la responsabilità sull’utilizzatore finale  
- Stimolare il confronto su errori e casi reali, senza giudizio  
- Evitare toni allarmistici o moralistici  
- Collegare il modulo alle esperienze concrete del pubblico

---

## 9. Tempistiche
Durata totale consigliata: **60 minuti**

- Introduzione e contesto: 10 minuti  
- Spiegazione dei concetti: 25 minuti  
- Esempi pratici: 15 minuti  
- Interazione ed esercizi: 10 minuti

---

## 10. Strumenti e materiali
- Slide di supporto (opzionali)  
- Schede con casi di esempio (facoltative)  
- Lavagna o supporto per annotare riflessioni del pubblico

Tutti gli strumenti sono opzionali.

---

## 11. Note operative
- Livello di difficoltà: base  
- Nessun prerequisito tecnico richiesto  
- Modulo complementare al Modulo 1  
- Può essere accorciato riducendo l’esercizio o ampliato con più casi  
- Utile come ponte tra moduli introduttivi e moduli pratici

